{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ac81893-fd8f-43b1-9cea-53398745cab4",
   "metadata": {},
   "source": [
    "# Demo Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93f249b-c224-4e7c-8ba2-44d559198892",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e430432-90db-4a1d-95e0-90e1cc86ad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/technet/miniconda3/envs/technet/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772f0825-179e-4a7c-980b-00e17e23df4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 16.0k/16.0k [00:00<00:00, 9.69MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 412k/412k [00:00<00:00, 924kB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 413k/413k [00:00<00:00, 1.39MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 19.6M/19.6M [00:00<00:00, 26.3MB/s]\n",
      "Generating test split: 100%|█████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 305384.54 examples/s]\n",
      "Generating validation split: 100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 905740.69 examples/s]\n",
      "Generating train split: 100%|█████████████████████████████████████████████████████████████████████████████| 550152/550152 [00:00<00:00, 1785507.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('snli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8cdd79-e421-4a88-8709-f29e63771341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550147</th>\n",
       "      <td>Four dirty and barefooted children.</td>\n",
       "      <td>four kids won awards for 'cleanest feet'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550148</th>\n",
       "      <td>Four dirty and barefooted children.</td>\n",
       "      <td>four homeless children had their shoes stolen,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550149</th>\n",
       "      <td>A man is surfing in a bodysuit in beautiful bl...</td>\n",
       "      <td>A man in a bodysuit is competing in a surfing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550150</th>\n",
       "      <td>A man is surfing in a bodysuit in beautiful bl...</td>\n",
       "      <td>A man in a business suit is heading to a board...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550151</th>\n",
       "      <td>A man is surfing in a bodysuit in beautiful bl...</td>\n",
       "      <td>On the beautiful blue water there is a man in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550152 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  premise  \\\n",
       "0       A person on a horse jumps over a broken down a...   \n",
       "1       A person on a horse jumps over a broken down a...   \n",
       "2       A person on a horse jumps over a broken down a...   \n",
       "3                   Children smiling and waving at camera   \n",
       "4                   Children smiling and waving at camera   \n",
       "...                                                   ...   \n",
       "550147                Four dirty and barefooted children.   \n",
       "550148                Four dirty and barefooted children.   \n",
       "550149  A man is surfing in a bodysuit in beautiful bl...   \n",
       "550150  A man is surfing in a bodysuit in beautiful bl...   \n",
       "550151  A man is surfing in a bodysuit in beautiful bl...   \n",
       "\n",
       "                                               hypothesis  label  \n",
       "0       A person is training his horse for a competition.      1  \n",
       "1           A person is at a diner, ordering an omelette.      2  \n",
       "2                       A person is outdoors, on a horse.      0  \n",
       "3                       They are smiling at their parents      1  \n",
       "4                              There are children present      0  \n",
       "...                                                   ...    ...  \n",
       "550147           four kids won awards for 'cleanest feet'      2  \n",
       "550148  four homeless children had their shoes stolen,...      1  \n",
       "550149  A man in a bodysuit is competing in a surfing ...      1  \n",
       "550150  A man in a business suit is heading to a board...      2  \n",
       "550151  On the beautiful blue water there is a man in ...      0  \n",
       "\n",
       "[550152 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c99d266b-2952-4dbd-8ab9-53a833710567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>The sisters are hugging goodbye while holding ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>Two woman are holding packages.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two women are embracing while holding to go pa...</td>\n",
       "      <td>The men are fighting outside a deli.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two young children in blue jerseys, one with t...</td>\n",
       "      <td>Two kids in numbered jerseys wash their hands.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two young children in blue jerseys, one with t...</td>\n",
       "      <td>Two kids at a ballgame wash their hands.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>A small girl wearing a pink jacket is riding o...</td>\n",
       "      <td>The girl is sitting on a carved horse made of ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>A small girl wearing a pink jacket is riding o...</td>\n",
       "      <td>The girl is moving at the speed of light.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>A young girl with blue and pink ribbons in her...</td>\n",
       "      <td>People in a water fountain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>A young girl with blue and pink ribbons in her...</td>\n",
       "      <td>A young girl knits a sweater</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>A young girl with blue and pink ribbons in her...</td>\n",
       "      <td>A young mother tries to grab her topless child...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     Two women are embracing while holding to go pa...   \n",
       "1     Two women are embracing while holding to go pa...   \n",
       "2     Two women are embracing while holding to go pa...   \n",
       "3     Two young children in blue jerseys, one with t...   \n",
       "4     Two young children in blue jerseys, one with t...   \n",
       "...                                                 ...   \n",
       "9995  A small girl wearing a pink jacket is riding o...   \n",
       "9996  A small girl wearing a pink jacket is riding o...   \n",
       "9997  A young girl with blue and pink ribbons in her...   \n",
       "9998  A young girl with blue and pink ribbons in her...   \n",
       "9999  A young girl with blue and pink ribbons in her...   \n",
       "\n",
       "                                             hypothesis  label  \n",
       "0     The sisters are hugging goodbye while holding ...      1  \n",
       "1                       Two woman are holding packages.      0  \n",
       "2                  The men are fighting outside a deli.      2  \n",
       "3        Two kids in numbered jerseys wash their hands.      0  \n",
       "4              Two kids at a ballgame wash their hands.      1  \n",
       "...                                                 ...    ...  \n",
       "9995  The girl is sitting on a carved horse made of ...     -1  \n",
       "9996          The girl is moving at the speed of light.      2  \n",
       "9997                         People in a water fountain      0  \n",
       "9998                       A young girl knits a sweater      2  \n",
       "9999  A young mother tries to grab her topless child...      1  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50672cd4-9046-47ef-b5ff-dc838b7a3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, unicode_literals\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import logging\n",
    "import sklearn\n",
    "import torch\n",
    "\n",
    "# Set PATHs\n",
    "# path to senteval\n",
    "PATH_TO_SENTEVAL = 'SentEval/'\n",
    "# path to the NLP datasets \n",
    "PATH_TO_DATA = 'SentEval/data/'\n",
    "# path to glove embeddings\n",
    "PATH_TO_VEC = 'pretrained/glove.840B.300d.txt'\n",
    "\n",
    "# import SentEval\n",
    "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "import senteval\n",
    "from encoders.word_embeddings_mean import WordEmbeddingsMeanEncoder\n",
    "from utils.word_embeddings import create_dictionary, get_wordvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f6643ce-3846-43c0-bada-5f7308fc8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['hello', 'it', 'is', 'your', 'mother'], ['i', 'really', 'like', 'your', 'mothers', 'pancake']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de1b02c7-2b43-4b68-b7c5-10f583e0a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word, word2id = create_dictionary(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b120b171-0d17-42da-a4fc-bda3d88f601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = get_wordvec(PATH_TO_VEC, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57dcbb91-2c0f-45fc-b8d3-e95b343dec12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.4961e-02,  5.0200e-01,  2.3823e-03, -1.6755e-01,  3.0721e-01,\n",
       "       -2.3762e-01,  1.6069e-01, -3.6786e-01, -5.8347e-02,  2.4990e+00,\n",
       "       -2.3647e-03,  1.0732e-02, -3.0422e-01,  8.4579e-02, -4.0299e-02,\n",
       "       -4.1562e-01, -2.4494e-02,  1.4691e+00, -5.2932e-02, -7.4413e-02,\n",
       "       -3.9244e-01, -3.2535e-01, -2.2333e-01,  5.6823e-03,  3.5675e-01,\n",
       "        1.9445e-01,  5.6762e-02, -4.5502e-02, -2.8105e-01, -5.8896e-02,\n",
       "       -9.8626e-02,  9.2177e-02,  3.3172e-01, -3.9967e-02, -1.1766e-01,\n",
       "        4.8373e-02, -6.2241e-02, -1.0413e-01,  9.9263e-04, -4.8925e-01,\n",
       "        3.4786e-01,  3.2724e-01,  1.3882e-01, -1.9917e-01,  1.2995e-01,\n",
       "        6.0549e-02, -2.3714e-01, -5.1295e-01, -3.7396e-01,  1.2902e-01,\n",
       "        5.5797e-02,  3.3444e-01, -1.8025e-01, -3.4740e-02,  2.8323e-01,\n",
       "       -9.5301e-02,  2.1143e-01, -7.6149e-02,  1.5069e-01, -1.7441e-01,\n",
       "       -7.4768e-03, -7.8287e-02, -1.2751e-01,  2.2545e-01,  3.5101e-02,\n",
       "       -6.1015e-01, -2.6812e-01,  6.1632e-02, -3.0503e-01, -1.3405e-01,\n",
       "       -4.4271e-01, -1.7720e-01,  1.7663e-01, -3.1210e-01, -2.5722e-01,\n",
       "       -2.4858e-02,  7.2504e-02, -7.9759e-02, -1.9214e-01,  5.9602e-01,\n",
       "        1.2880e-01, -7.4629e-02, -1.5812e-01,  3.6394e-01,  2.3055e-01,\n",
       "       -4.2175e-01, -9.0651e-02, -3.0085e-01,  1.7940e-01, -2.9786e-01,\n",
       "       -1.0642e-01,  4.7239e-01, -1.3837e-01, -1.0161e-01,  8.0134e-02,\n",
       "        4.0715e-02, -3.6976e-01, -3.7066e-02,  1.0436e-01,  1.7904e-01,\n",
       "        1.5702e-01, -7.4670e-02, -2.9431e-01,  1.2829e-01,  5.5211e-02,\n",
       "       -4.3906e-01, -6.8231e-02,  9.7107e-02, -2.8209e-01, -8.6528e-02,\n",
       "       -2.4204e-01,  2.8734e-02, -2.1509e-01,  2.7152e-02, -1.7996e-01,\n",
       "        1.9317e-01, -2.7929e-01,  2.9415e-01, -1.0965e-01, -1.0432e-01,\n",
       "       -5.2170e-01, -4.6789e-02,  1.3743e-01, -1.5518e-01, -1.0359e-01,\n",
       "        1.8853e-01, -1.2684e-01, -6.7278e-01,  3.4483e-02, -2.2937e-01,\n",
       "       -9.8073e-02, -7.0157e-02,  8.4374e-02,  2.6594e-01,  2.3104e-01,\n",
       "       -2.9251e-01, -8.7209e-02, -2.3342e-01,  6.3759e-02, -1.3556e-01,\n",
       "       -8.4046e-01,  2.4681e-01,  3.0498e-01,  3.5438e-01,  1.4137e-01,\n",
       "       -3.6720e-01,  2.3321e-01, -1.5497e-01,  4.8364e-01,  1.4711e-02,\n",
       "       -2.4176e-01,  3.7589e-02,  1.9829e-01, -6.9403e-02, -1.7362e-03,\n",
       "        4.1694e-02, -3.4193e-01, -2.0034e-01, -4.5581e-01, -1.2504e-01,\n",
       "        1.3954e-01,  3.2275e-02, -5.2130e-03,  4.5422e-02, -2.6574e-03,\n",
       "       -2.6266e-01,  6.4168e-02, -1.4231e-01,  3.5709e-04, -2.3253e-01,\n",
       "        2.7615e-02, -7.4282e-02,  1.8671e-01, -1.2994e-01, -4.3731e-01,\n",
       "        1.4550e-01,  4.4838e-02, -1.9022e-01, -1.5401e-01,  1.4188e-01,\n",
       "        9.8269e-02, -4.2930e-02, -2.7478e-01, -3.3224e-01, -3.2167e-01,\n",
       "       -1.0509e-01, -1.9816e-01, -6.5097e-02, -9.1251e-02,  1.9528e-01,\n",
       "       -3.3297e-01, -1.5504e-01, -4.7688e-01,  3.1985e-01,  1.9886e-01,\n",
       "        1.1501e-01,  5.5757e-02, -5.4307e-02,  2.8851e-01,  2.7982e-01,\n",
       "        1.3960e-02, -1.2891e-03, -2.3128e-01,  7.5396e-02,  4.3587e-02,\n",
       "       -1.3937e-01, -6.2935e-02,  1.2568e-01,  9.5235e-02, -8.5203e-02,\n",
       "       -2.4241e-01, -4.8771e-02,  9.5937e-02, -2.2347e-01,  2.3503e-01,\n",
       "        3.1517e-01, -1.4900e-02,  2.1739e-01, -1.9431e-01, -2.3255e-01,\n",
       "       -2.2961e-01,  4.8297e-02,  1.6050e-01, -1.6100e-02,  4.2770e-02,\n",
       "       -3.2367e-01,  1.4680e-01,  2.4551e-01,  7.5506e-02, -3.9703e-02,\n",
       "       -1.0321e-01,  1.6194e-01,  2.7132e-01,  4.6348e-02, -9.2743e-02,\n",
       "       -1.4929e-01,  2.7378e-01, -3.6958e-01, -4.1530e-01,  1.8402e-01,\n",
       "       -4.9775e-02,  6.9670e-02,  1.3447e-01,  1.7788e-01, -4.7586e-02,\n",
       "       -3.6491e-01, -1.3733e-01, -4.8119e-01,  2.4681e-01, -8.9842e-02,\n",
       "        3.7939e-02, -1.8284e-01,  4.7012e-01, -9.9584e-02, -1.8365e-01,\n",
       "       -7.1821e-02,  4.1607e-01, -1.8581e-01,  1.8400e-01, -2.9028e-02,\n",
       "        4.1228e-01,  2.2856e-02,  5.0915e-02, -1.1911e-01,  8.1231e-02,\n",
       "        1.3845e-01,  4.6595e-02, -4.3974e-02,  6.3601e-01,  3.7101e-03,\n",
       "        9.3937e-02, -9.3442e-02, -4.7606e-01, -2.6427e-01, -2.3044e-02,\n",
       "       -5.8241e-02,  1.1440e-01, -5.1702e-02,  3.5225e-01,  2.5341e-01,\n",
       "        5.7256e-01,  2.2867e-01,  8.5401e-03, -6.2531e-02, -3.2118e-02,\n",
       "       -1.5647e-01, -8.4344e-02,  7.6667e-02,  3.4515e-01, -1.9452e-01,\n",
       "        8.7003e-02, -7.8201e-02, -6.9673e-02, -1.6993e-01,  2.3598e-01,\n",
       "        2.7550e-01, -6.7180e-02, -2.1511e-01, -2.6304e-01, -6.0173e-03])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec['is']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407db48-8b3e-4b6e-a1b1-a25a4339476a",
   "metadata": {},
   "source": [
    "# 1. Run SentEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cc422e71-e1ea-4e19-b19a-be9e217928ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoders.lstm.unidirectional_lstm import UnidirectionalLSTMEncoder\n",
    "from encoders.lstm.bidirectional_lstm import BidirectionalLSTMEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4cdaa94f-b712-49cb-909f-0e9c775eead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoder = BidirectionalLSTMEncoder(pooling_type='max') # UnidirectionalLSTMEncoder() # WordEmbeddingsMeanEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cfe4f005-6e26-4c32-90b1-e390a8981ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = ['hello', 'it', 'is', 'your', 'mother']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "66b9f650-2507-41b0-abbb-5b2e2a1f1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.Tensor([[word2vec[word] for word in test_sentence]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c37c0108-fef8-4717-a182-d9fa77267769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 300])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dab904d0-e4c8-411a-bc20-a2e0677e3559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_encoder.forward((embeddings, [5]))[0].detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0b03eeca-9858-4e25-ac96-d1a10242eba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_encoder.forward((embeddings, [5])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1c93822e-ef62-4a55-954d-990532512a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.word_embeddings import get_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49e96d98-3135-449f-818c-ad2b9cd16c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentEval prepare and batcher\n",
    "def prepare(params, samples):\n",
    "    _, params.word2id = create_dictionary(samples)\n",
    "    params.word_vec = get_wordvec(PATH_TO_VEC, params.word2id)\n",
    "    params.wvec_dim = 300\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    batch = [sent if sent != [] else ['.'] for sent in batch]\n",
    "    embeddings = []\n",
    "\n",
    "    for sent in batch:\n",
    "        word_embeddings = get_word_embeddings(params.word_vec, sent)\n",
    "        if isinstance(sentence_encoder, WordEmbeddingsMeanEncoder):\n",
    "            sentvec = sentence_encoder.forward(torch.Tensor([word_embeddings]))[0].detach().numpy()\n",
    "        else:\n",
    "            sentvec = sentence_encoder.forward((torch.Tensor([word_embeddings]), [len(sent)]))[0].detach().numpy()\n",
    "        embeddings.append(sentvec)\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8093cbf6-835c-4f02-89c0-1aa422826d93",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m transfer_tasks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMRPC\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# senteval prints the results and returns a dictionary with the scores\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransfer_tasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m~/UVA/ATCS/SentenceRepresentationsCodebase/SentEval/senteval/engine.py:59\u001b[0m, in \u001b[0;36mSE.eval\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# evaluate on evaluation [name], either takes string or list of strings\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m---> 59\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\n\u001b[1;32m     62\u001b[0m     tpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mtask_path\n",
      "File \u001b[0;32m~/UVA/ATCS/SentenceRepresentationsCodebase/SentEval/senteval/engine.py:59\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# evaluate on evaluation [name], either takes string or list of strings\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m---> 59\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m {x: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m name}\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\n\u001b[1;32m     62\u001b[0m     tpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mtask_path\n",
      "File \u001b[0;32m~/UVA/ATCS/SentenceRepresentationsCodebase/SentEval/senteval/engine.py:121\u001b[0m, in \u001b[0;36mSE.eval\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mcurrent_task \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation\u001b[38;5;241m.\u001b[39mdo_prepare(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\n",
      "File \u001b[0;32m~/UVA/ATCS/SentenceRepresentationsCodebase/SentEval/senteval/mrpc.py:74\u001b[0m, in \u001b[0;36mMRPCEval.run\u001b[0;34m(self, params, batcher)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(text_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]), params\u001b[38;5;241m.\u001b[39mbatch_size):\n\u001b[1;32m     73\u001b[0m     batch \u001b[38;5;241m=\u001b[39m text_data[txt_type][ii:ii \u001b[38;5;241m+\u001b[39m params\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m---> 74\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mbatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     mrpc_embed[key][txt_type]\u001b[38;5;241m.\u001b[39mappend(embeddings)\n\u001b[1;32m     76\u001b[0m mrpc_embed[key][txt_type] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(mrpc_embed[key][txt_type])\n",
      "Cell \u001b[0;32mIn[52], line 17\u001b[0m, in \u001b[0;36mbatcher\u001b[0;34m(params, batch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         sentvec \u001b[38;5;241m=\u001b[39m sentence_encoder\u001b[38;5;241m.\u001b[39mforward(torch\u001b[38;5;241m.\u001b[39mTensor([word_embeddings]))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m         sentvec \u001b[38;5;241m=\u001b[39m \u001b[43msentence_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword_embeddings\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     18\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(sentvec)\n\u001b[1;32m     20\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(embeddings)\n",
      "File \u001b[0;32m~/UVA/ATCS/SentenceRepresentationsCodebase/encoders/lstm/unidirectional_lstm.py:27\u001b[0m, in \u001b[0;36mUnidirectionalLSTMEncoder.forward\u001b[0;34m(self, sentences_length_tuple)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# pack sentences\u001b[39;00m\n\u001b[1;32m     25\u001b[0m packed_sentences \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpack_padded_sequence(sorted_sentences, sorted_lengths, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked_sentences\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m _, idx_unsort \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msort(idx_sort)\n\u001b[1;32m     30\u001b[0m unsorted_output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;241m0\u001b[39m, idx_unsort)\n",
      "File \u001b[0;32m~/miniconda3/envs/technet/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/technet/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/technet/lib/python3.11/site-packages/torch/nn/modules/rnn.py:882\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    879\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    880\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m output \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    885\u001b[0m hidden \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set params for SentEval\n",
    "# we use logistic regression (usepytorch: Fasle) and kfold 10\n",
    "# In this dictionary you can add extra information that you model needs for initialization\n",
    "# for example the path to a dictionary of indices, of hyper parameters\n",
    "# this dictionary is passed to the batched and the prepare fucntions\n",
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': False, 'kfold': 4}\n",
    "# this is the config for the NN classifier but we are going to use scikit-learn logistic regression with 10 kfold\n",
    "# usepytorch = False \n",
    "# params_senteval['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n",
    "#                                 'tenacity': 3, 'epoch_size': 2}\n",
    "\n",
    "# Set up logger\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.DEBUG)\n",
    "\n",
    "se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "\n",
    "# here you define the NLP taks that your embedding model is going to be evaluated\n",
    "# in (https://arxiv.org/abs/1802.05883) we use the following :\n",
    "# SICKRelatedness (Sick-R) needs torch cuda to work (even when using logistic regression), \n",
    "# but STS14 (semantic textual similarity) is a similar type of semantic task\n",
    "transfer_tasks = ['MRPC']\n",
    "# senteval prints the results and returns a dictionary with the scores\n",
    "results = se.eval(transfer_tasks)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a5fc8-4e80-46d2-9a93-b6dc83482796",
   "metadata": {},
   "outputs": [],
   "source": [
    "results # WordMean: 0.746 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad2316-22d0-43d7-9ab2-f3863e3c21ac",
   "metadata": {},
   "source": [
    "# 2. Run SNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7b4f919-8158-4761-8567-9ad68ed5cd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/technet/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils.snli_data import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc05e82c-36c5-49c8-9fcb-69eec96ee53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.93 ms, sys: 0 ns, total: 8.93 ms\n",
      "Wall time: 9.09 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hello', 'whats', 'up', 'i', 'miss', 'you']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preprocess_text(\"\"\"hello what's up? I miss you.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dcafb7-e461-47e3-bf0f-0a3854079456",
   "metadata": {},
   "source": [
    "# Train on SNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62abd4ff-9a32-4cbf-9702-888ec8a636a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47d5032a-f4f3-4603-81a5-567b5ef31a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.snli_data import get_snli_data\n",
    "from heads.snli_model import SNLIClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "14f0c483-2eb4-4000-903c-68d9ecea3604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train\n",
      "sampling...\n",
      "tokenizing sentence 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:01<00:00, 13154.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing sentence 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:01<00:00, 16971.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading dev\n",
      "tokenizing sentence 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 13494.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing sentence 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 16647.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading test\n",
      "tokenizing sentence 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 12932.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing sentence 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 16143.49it/s]\n"
     ]
    }
   ],
   "source": [
    "train = get_snli_data(split='train', sample=20_000)\n",
    "valid = get_snli_data(split='dev')\n",
    "test = get_snli_data(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22c82b23-c90b-458d-ac5f-5b61ec6f5420",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = list(train['sentence1']) + list(train['sentence2']) +\\\n",
    "                list(valid['sentence1']) + list(valid['sentence2']) +\\\n",
    "                list(test['sentence1']) + list(test['sentence2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f0d939a-a1cf-4120-a319-3e12456ec1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word, word2id = create_dictionary(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57ade9f8-bb71-484d-a825-59ed2075ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longest_sentence(sentences):\n",
    "    return np.max([len(s) for s in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "504646cf-023b-486a-9209-b898fe4e06aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = get_longest_sentence(all_sentences)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3c38dde4-d3c5-4fe8-b4d8-86cfbfc652b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = get_wordvec(PATH_TO_VEC, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e29ec488-d5c5-478c-b575-1f6e0a06ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_model = SNLIClassifier(encoder=BidirectionalLSTMEncoder(encoding_lstm_dim=256, pooling_type='max'), embedding_dim=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b8c64044-0fc5-4475-80c4-e1273766d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=nli_model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f0d7657f-47c2-4cb9-94b2-3da2f476342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6c7f54b0-bfe0-4108-bcc8-72f285305429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_snli import train_one_epoch\n",
    "from utils.eval import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8928ad42-8923-4a57-bdaa-bc4bef851570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [02:18,  2.26it/s]                                                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0934857518528216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:13, 11.08it/s]                                                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.3330623856939646}\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [01:58,  2.64it/s]                                                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0346849916842038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:11, 13.87it/s]                                                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.3382442592968909}\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [01:56,  2.68it/s]                                                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.872105002212829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:11, 13.85it/s]                                                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5308880308880309}\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [02:04,  2.51it/s]                                                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7557682097910311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:10, 14.67it/s]                                                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5159520422678318}\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [02:04,  2.51it/s]                                                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6746816810922691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "154it [00:10, 14.62it/s]                                                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6588091851249746}\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████████████▎                                                                                               | 75/312 [00:30<01:36,  2.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch)\n\u001b[0;32m----> 3\u001b[0m     loss_batches \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnli_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword2vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuple_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(loss_batches))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(evaluate_model(nli_model, valid, word2vec, BATCH_SIZE, tuple_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/UVA/ATCS/SentenceRepresentationsCodebase/train_snli.py:47\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(nli_model, train, optimizer, loss_fn, word2vec, batch_size, tuple_input)\u001b[0m\n\u001b[1;32m     44\u001b[0m     all_costs\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# backward\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_costs\n",
      "File \u001b[0;32m~/miniconda3/envs/technet/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/technet/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print('epoch', epoch)\n",
    "    loss_batches = train_one_epoch(nli_model, train, optimizer, loss_fn, word2vec, BATCH_SIZE, tuple_input=True)\n",
    "    print(np.mean(loss_batches))\n",
    "    print(evaluate_model(nli_model, valid, word2vec, BATCH_SIZE, tuple_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449cf70-657a-4c0f-bf6f-d60ef4253b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
